{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 800 images d'entrainement de patient covid.\n",
      "Il y a 1200 images d'entrainement de patient non-covid.\n",
      "Il y a 201 images de validation de patient covid.\n",
      "Il y a 301 images de validation de patient non-covid.\n",
      "Il y a 1143 images test de patient covid.\n",
      "Il y a 2686 images test de patient non-covid.\n"
     ]
    }
   ],
   "source": [
    "# On déclare les chemins vers les données :\n",
    "\n",
    "Image = 'Data'\n",
    "        \n",
    "test_data_dir = 'Data/TEST'\n",
    "train_data_dir = 'Data/TRAIN'\n",
    "validation_data_dir = 'Data/VALIDATION'\n",
    "\n",
    "# Dimensions et path :\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "ImageTRAINCOVID = os.listdir(Image + '/TRAIN/A_COVID')\n",
    "ImageTRAINAUTRE = os.listdir(Image + '/TRAIN/B_AUTRE')\n",
    "\n",
    "ImageVALIDATIONCOVID = os.listdir(Image + '/VALIDATION/A_COVID')\n",
    "ImageVALIDATIONAUTRE = os.listdir(Image + '/VALIDATION/B_AUTRE')\n",
    "\n",
    "ImageTESTCOVID = os.listdir(Image + '/TEST/A_COVID')\n",
    "ImageTESTAUTRE = os.listdir(Image + '/TEST/B_AUTRE')\n",
    "\n",
    "print('Il y a ' + str(len(ImageTRAINCOVID)) + ' images d\\'entrainement de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTRAINAUTRE)) + ' images d\\'entrainement de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONCOVID)) + ' images de validation de patient covid.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONAUTRE)) + ' images de validation de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageTESTCOVID)) + ' images test de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTESTAUTRE)) + ' images test de patient non-covid.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 502 images belonging to 2 classes.\n",
      "Found 3829 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# pré-processing\n",
    "\n",
    "# On rescale les images :\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# On définit la batch size :\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "# On prépare les tableaux de données depuis les images :\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 52, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2768960   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,797,665\n",
      "Trainable params: 2,797,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# On définit l'architecture du modèle :\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# On compile le modèle :\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# On affiche le modèle :\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit les paramètres pour l'entrainement :\n",
    "epochs = 100\n",
    "train_samples = 2000\n",
    "validation_samples = 502\n",
    "test_samples = 3829\n",
    "\n",
    "# On définit les callbacks : \n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min',patience = 10,restore_best_weights=True,),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 414s 7s/step - loss: 0.6456 - accuracy: 0.7978 - val_loss: 0.2973 - val_accuracy: 0.9083\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 330s 5s/step - loss: 0.1581 - accuracy: 0.9558 - val_loss: 0.3896 - val_accuracy: 0.8604\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 491s 8s/step - loss: 0.2352 - accuracy: 0.9522 - val_loss: 0.2499 - val_accuracy: 0.9167\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 616s 10s/step - loss: 0.0901 - accuracy: 0.9726 - val_loss: 0.2317 - val_accuracy: 0.9229\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 602s 10s/step - loss: 0.1078 - accuracy: 0.9721 - val_loss: 0.2590 - val_accuracy: 0.9167\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 303s 5s/step - loss: 0.0614 - accuracy: 0.9812 - val_loss: 0.1084 - val_accuracy: 0.9646\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 263s 4s/step - loss: 0.0715 - accuracy: 0.9817 - val_loss: 0.2858 - val_accuracy: 0.9167\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 260s 4s/step - loss: 0.0560 - accuracy: 0.9868 - val_loss: 0.2716 - val_accuracy: 0.9292\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 257s 4s/step - loss: 0.0481 - accuracy: 0.9878 - val_loss: 0.1815 - val_accuracy: 0.9667\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 262s 4s/step - loss: 0.0360 - accuracy: 0.9898 - val_loss: 0.6875 - val_accuracy: 0.8542\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 258s 4s/step - loss: 0.1186 - accuracy: 0.9817 - val_loss: 0.3502 - val_accuracy: 0.9312\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 260s 4s/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.3498 - val_accuracy: 0.9312\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 261s 4s/step - loss: 0.1048 - accuracy: 0.9822 - val_loss: 0.2931 - val_accuracy: 0.9438\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 254s 4s/step - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.5527 - val_accuracy: 0.8729\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 252s 4s/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 0.3247 - val_accuracy: 0.9021\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 252s 4s/step - loss: 0.0097 - accuracy: 0.9954 - val_loss: 0.4153 - val_accuracy: 0.9187\n"
     ]
    }
   ],
   "source": [
    "# Entrainement du modèle :\n",
    "\n",
    "historique = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks = my_callbacks,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_samples// batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la generation optimale est :  6\n"
     ]
    }
   ],
   "source": [
    "n_epochs = len(historique.history['loss'])\n",
    "GenOptimale = n_epochs-10\n",
    "print(\"la generation optimale est : \",GenOptimale)\n",
    "model.save_weights('models/Weights/scratch_224_224_'+str(GenOptimale)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testImage(path):\n",
    "    img = load_img(path, target_size=(224,224))\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    y = model.predict(img)\n",
    "    return y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On évalue le modèle sur les données de validation :\n",
    "\n",
    "resultValidation = model.evaluate_generator(validation_generator, validation_samples)\n",
    "\n",
    "# On évalue le modèle sur les données de test :\n",
    "\n",
    "resultTest = model.evaluate_generator(test_generator, test_samples)1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/baudouin/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/scratchFull_10G_224_224/assets\n"
     ]
    }
   ],
   "source": [
    "# On enregistre l'historique et les poids :\n",
    "\n",
    "model.save_weights('models/scratch_10G_224_224.h5')\n",
    "\n",
    "np.save('models/historique_scratch_224_224_10G_Baudouin.npy',historique.history)\n",
    "\n",
    "model.save('models/scratchFull_10G_224_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
